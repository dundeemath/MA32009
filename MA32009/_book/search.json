[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA32009",
    "section": "",
    "text": "Preface\nWelcome to MA32009 (Mathematical Biology I).\nMy name is Philip Murray and I am the module lead."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-general-model-for-a-single-population-in-discrete-time",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-general-model-for-a-single-population-in-discrete-time",
    "title": "1  Single species population dynamics",
    "section": "1.1 A general model for a single population in discrete time",
    "text": "1.1 A general model for a single population in discrete time\nLet \\(t\\) be an independent variable representing time and \\(N_t\\) be a dependent variable representing the size of the population of a given species at time \\(t\\).\nConsider the first order difference equation \\[\nN_{t+1}=N_tf(N_t)=H(N_t),\n\\tag{1.1}\\] where \\(f(N_t)\\) is a function that defines the per capita growth rate. The function \\(H(N_t)\\) describes the total (net) growth rate.\nGiven some initial condition \\(N_0\\) defined such that \\[\nN_{t=0}=N_0,\n\\] the goal of this section is to develop a range of techniques that allow us to analyse the behaviour of Equation 1.1 for a given \\(H\\).\nFinally, note that many of you were introduced to difference equations in the module MA21003 Discrete Mathematics. It is recommended that you revisit the section on Discrete Difference Equations."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#the-malthusian-model",
    "href": "MA32009-SinglePopDiscreteTimea.html#the-malthusian-model",
    "title": "1  Single species population dynamics",
    "section": "1.2 The Malthusian model",
    "text": "1.2 The Malthusian model\nPerhaps the simplest form for equation Equation 1.1 is when the net per capita growth rate is a constant.\nLet \\(b\\) be the per capita growth rate and \\(d\\) the per capita death rate with \\(b\\) and \\(d\\) both positive real constants.\nHence, a population of size \\(N_t\\) at time \\(t\\) will grow by \\[\nbN_t\n\\] over the course of the next iteration and decay by\n\\[\ndN_t.\n\\] Therefore the population size at time \\(t+1\\) is \\[\nN_{t+1}=N_t + bN_t - dN_t=rN_t,\n\\tag{1.2}\\] where the parameter \\(r=1+b-d\\) is known as the net growth rate.\nGiven the initial condition \\(N_0\\), equation Equation 1.2 can be solved recursively as follows:\n\\[\nN_1=rN_0,\nN_2=r(N_1)=r^2N_0,   \nN_3=rN_2=r^3N_0, ...,    \nN_t=r^tN_0.\n\\] Hence for the case of Malthusian growth, the size of the population can be explicitly calculated for all \\(t\\).\nIn Figure 1.1 a numerical solution of the model is computed for different values of the parameter \\(r\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=3.0\nr=0.5\nr_2=1.5\n\ndef rhs(x,r):\n  f=r*x\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r) \n  return N\n\nN=SolveSingleDiff(t,rhs,N_0,r)\nN_2=SolveSingleDiff(t,rhs,N_0,r_2)\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(t, N)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.1: A plot of the Malthusian model solution when (a) \\(r\\)=0.5 and (b) \\(r\\)=1.5.\n\n\n\n\nCan you describe the behaviour of the Malthusian model? How does it depend on the value of the parameter \\(r\\)?\nQualitative analyses allows us to categorise solution behaviours into different cases. For example, note that the behaviour of the population at large \\(t\\) is governed by the magnitude of the parameter \\(r\\).\nAs \\(t\\rightarrow \\infty\\)\n\\[\nN \\rightarrow\n\\left\\{\n\\begin{array}{ll}\n\\infty & r&gt;1  \\\\\nN_0& r=1  \\\\  \n0 & r&lt;1.     \n\\end{array} \\right.\n\\]\nIn Figure 1.1 solutions in each of the (nontrivial) parameter regimes are plotted. When \\(r&lt;1\\) the population tends to zero and when \\(r&gt;1\\) the population explodes.\nWhilst the simplicity of the Malthusian model allows us to calculate explicit solutions that yield insight into how the processes of birth and death combine to give either net growth or net reduction in population size, an obvious flaw with this model is that it displays unbounded growth for \\(r&gt;1\\). In most biological systems, other effects, such as competition for resources or predation, will tend to limit a population’s size. In single species population models, these effects are accounted for phenomenologically by introducing nonlinear terms into the function \\(f\\)."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-motivating-example-of-a-nonlinear-model---the-ricker-model",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-motivating-example-of-a-nonlinear-model---the-ricker-model",
    "title": "1  Single species population dynamics",
    "section": "1.3 A motivating example of a nonlinear model - The Ricker model",
    "text": "1.3 A motivating example of a nonlinear model - The Ricker model\nMany models of population dynamics in discrete time were initially developed to study fisheries. Well-studied examples include the Beverton Holt model \\[\nN_{t+1}=\\frac{rN_t}{1+\\frac{N_t}{K}},\n\\] the Hassell model \\[\nN_{t+1}=\\frac{rN_t}{(1+\\frac{N_t}{K})^b},\n\\] and the Ricker model \\[\nN_{t+1}=N_te^{r(1-\\frac{N_t}{K})}.\n\\] where \\(r\\), \\(K\\) and \\(b\\) are positive parameters. Below we consider the Ricker model which was initially used to study Canadian sockeye salmon population dynamics.\n\n1.3.1 Model development\nOne way to capture a decreased growth rate at high densities, is to assume that the per capita growth rate is an exponentially decreasing function of population density, i.e.  \\[\nf(N_t)=e^{r(1-\\frac{N_t}{K})},\n\\] where \\(r\\) is a growth rate and \\(K\\) a carrying capacity (both positive constants). Hence the governing equation is \\[\nN_{t+1}=N_te^{r(1-\\frac{N_t}{K})}.\n\\tag{1.3}\\] Note that as the population size gets large (\\(N_t\\gg K\\)), the growth rate tends to zero but that for small populations \\(N_t\\ll K\\) the growth rate is approximately constant. This is the Ricker model.\nNote that the model is nonlinear and does not have an explicit solution.\n\n\n1.3.2 Computational solutions\nAfter directly computing numerical solutions of the Ricker model for different values of the parameter \\(r\\), the data in (plotricker?) were obtained.\nNote that model behaviour changes drastically as the parameter \\(r\\) varies. For instance,\n\nwhen \\(r=0.5\\) (Figure 1.2 (a)), the solution monotonically approaches the value \\(2\\), *\nwhen \\(r=1.5\\) (Figure 1.2 (b)) it approaches two in an oscillatory manner; and\nwhen \\(r=2.5\\) (Figure 1.2 (c)) it oscillates around two.\n\nThe above numerical results raise the following questions:\n\ncan we develop tools that allow us to qualitatively describe how the model solutions depend on model parameters?\nare the there certain families of solutions with qualitatively similar behaviours?\nhow do such families of solutions depend on model parameters?\n\nWe will return to analysis of the Ricker model in Worksheet 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr_1=0.5\nr_2=1.5\nr_3=2.5\nK=2.0\n\nT=20\nt = np.arange(0, T, 1)\nN_1 = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\nN_3 = np.zeros_like(t,dtype=float)\n\ndef rhs(x,r,K):\n  \n  f=x*np.exp(r*(1-x/K))\n  return f\n\n\ndef SolveSingleDiff(t,rhs,N_0,r,K):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r,K) \n  return N\n\n\n\nN_1=SolveSingleDiff(t,rhs,N_0,r_1,K)\nN_2=SolveSingleDiff(t,rhs,N_0,r_2,K)\nN_3=SolveSingleDiff(t,rhs,N_0,r_3,K)\n\n\nfig, ax = plt.subplots(1,3)\nax[0].plot(t, N_1)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[2].plot(t, N_3)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.2: A plot of numerical solutions of the Ricker model. (a)r=0.5. (b) r=1.5. (c) r=2.5."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#general-techniques-for-analysing-nonlinear-difference-equations",
    "href": "MA32009-SinglePopDiscreteTimea.html#general-techniques-for-analysing-nonlinear-difference-equations",
    "title": "1  Single species population dynamics",
    "section": "1.4 General techniques for analysing nonlinear difference equations",
    "text": "1.4 General techniques for analysing nonlinear difference equations\nIn this section we develop techniques that will be used to analyse first order, discrete-time models of the form \\[\nN_{t+1}=N_t f(N_t)=H(N_t).\n\\tag{1.4}\\]\n\n1.4.1 Computational solutions\nPerhaps the most obvious way to investigate an equation of the form of Equation 1.4 is to iteratively compute \\(N_t\\) over a prescribed time range.\nHence given some initial population \\(N_0\\), the solution set \\(\\{N_0,N_1,N_2,...,N_T\\}\\) is computed up to some end time \\(T\\). Such an approach provides a numerical solution for a given parameter set and initial condition. However, it does not provide much insight into the general behaviour of model.\n\n\n1.4.2 Fixed points\nWe define \\(N^*\\) to be a fixed point of Equation 1.4 if and only if \\[\nN^*=N^*f(N^*)=H(N^*).\n\\] Hence the fixed points can be identified by solving an algebraic equation.\n\n\n1.4.3 Linear stability\nBy linearising about the identified fixed points using a Taylor series expansion, it can be determined whether or not small perturbations around the fixed point grow or decay in subsequent iterations.\nMaking a change of dependent variables \\[\nN_t=N^*+\\hat{N_t},\n\\] Equation 1.4 transforms upon substitution to \\[\nN^*+\\hat{N}_{t+1} =  H(N^*+\\hat{N}_t).\n\\]\nTaylor expanding the right-hand side yields \\[\nN^*+\\hat{N}_{t+1}= H(N^*)+H'(N^*)\\hat{N}_t + h.o.t. .\n\\]\nNoting that at the fixed point \\[\nN^*= H(N^*),\n\\] cancellation yields \\[\n\\hat{N}_{t+1} = H'(N^*)\\hat{N}_t + h.o.t.\n\\] Hence considering only small perturbations about the fixed point, the leading order behaviour of the perturbation is governed by \\[\n\\hat{N}_{t} = (H'(N^*))^t\\hat{N}_0.\n\\]\nHence the linear stability of the fixed point is governed by the sign and magnitude of the term \\(H'(N^*)\\). If \\[\n|H'(N^*)| &gt;1,\n\\] the fixed point is unstable. Otherwise it it stable.\n\n\n1.4.4 Cobwebbing and linear stability\nA cobweb diagram allows solutions of a first order difference equation to be sketched without explicitly solving.\n\n1.4.4.1 An algorithm for generating a cobweb diagram\nThe cobweb diagram is created as follows:\n\nPlot the \\(t^{th}\\) iterate, \\(N_t\\), on the \\(x\\) axis and the \\(t+1^{st}\\), \\(N_{t+1}\\) on the \\(y\\) axis.\nSketch the net growth rate function \\(H(N_t)\\).\nSketch the line \\(N_{t+1}=N_t\\).\nNote any intersections between the straight line and the graph of \\(H(N_t)\\) are fixed points.\nPlot the first point \\((N_0, H(N_0))\\) on the cobweb diagram.\nPlot a horizontal line between \\((N_0, H(N_0))\\) and \\((H(N_0),H(N_0))\\). Note \\(N_1=H(N_0)\\).\nPlot a vertical line between \\((N_1,N_1)\\) and \\((N_1,H(N_1))\\). *Repeat steps 6 and 7.\n\nPlotting cobweb diagrams in the vicinity of a fixed point \\(N^*\\) for different values of \\(H'(N^*)\\) allows us to see graphically how the derivative of the right-hand side affects linear stability of a fixed point (see Figure \\(\\ref{LinearStabilityDemo}\\)). In particular,\n\nwhen \\(H'(N^*)&gt;1\\), the fixed point is monotonically unstable;\nwhen \\(0&lt;H'(N^*)&lt;1\\), the fixed point is monotonically stable;\nwhen \\(-1&lt;H'(N^*)&lt;0\\), the fixed point is oscillatory stable;\nwhen \\(H'(N^*)=-1\\), the fixed point is oscillatory; and\nwhen \\(H'(N^*)&lt;-1\\), the fixed point is oscillatory unstable.\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=2.4\nr=0.5\nr_2=1.5\nN_max=2.5\nN_min=1.5\ndef rhs(x,r):\n  f=r*x+1\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n\n  num_time_steps=t.shape[0]\n\n  CobwebSol=np.zeros((2*num_time_steps,2))\n  CobwebSol[0,0]=N_0\n  CobwebSol[0,1]=rhs(N_0,r)\n  CobwebSol[1,0]=CobwebSol[0,1]\n  CobwebSol[1,1]=CobwebSol[0,1]\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r) \n\n      sol_temp=N[i-1]\n      rhs_temp=rhs(sol_temp,r)\n      CobwebSol[2*i,0]=sol_temp\n      CobwebSol[2*i,1]=rhs_temp\n      CobwebSol[2*i+1,0]=rhs_temp\n      CobwebSol[2*i+1,1]=rhs_temp\n  return N, CobwebSol\n\nN,CobwebSol=SolveSingleDiff(t,rhs,N_0,r)\n\nN_plot=np.linspace(N_min,N_max,100)\nH_N_plot=rhs(N_plot,r)\n\nfig, ax = plt.subplots(3,2)\nax[0,0].plot([N_min, N_max], [N_min, N_max])\nax[0,1].plot([N_min, N_max], [N_min, N_max])\nax[0,1].plot(N_plot, H_N_plot)\nax[1,0].plot([N_min, N_max], [N_min, N_max])\nax[1,0].plot(N_plot, H_N_plot)\nax[1,0].plot(CobwebSol[0,0], CobwebSol[0,1],'*')\nax[1,1].plot([N_min, N_max], [N_min, N_max])\nax[1,1].plot(N_plot, H_N_plot)\nax[1,1].plot(CobwebSol[0:5,0], CobwebSol[0:5,1])\nax[2,0].plot([N_min, N_max], [N_min, N_max])\nax[2,0].plot(N_plot, H_N_plot)\nax[2,0].plot(CobwebSol[0:7,0], CobwebSol[0:7,1])\nax[2,1].plot([N_min, N_max], [N_min, N_max])\nax[2,1].plot(N_plot, H_N_plot)\nax[2,1].plot(CobwebSol[:,0], CobwebSol[:,1])\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.3: Generating a cobweb plot.\n\n\n\n\n\n\n\n1.4.5 Bifurcation diagrams\nA bifurcation is a qualitative change in solution behaviour (either a change in the number of fixed points or their stability). A bifurcation diagram is a compact means of describing bifurcations as a function of model parameters. Usually, the fixed point value of the population (i.e. \\(N^*\\)) is plotted against a model parameter of interest. From this diagram one can immediately see how the number of fixed points and their stability changes as a given parameter increases.\n\n\n1.4.6 Perform a qualitative analysis on the Matlhusian model\nLet’s work through the various concepts introduced above using the Malthusian model (Equation 1.2).\nThe fixed points satisfy \\[\nN^*=rN^*.\n\\] As \\(r&gt;0\\) the only solution is \\(N^*=0\\).\nIn this case \\[\nH'(N_t)=r.\n\\] Hence the linear stability of the solution depends on the value of the parameter \\(r\\) For \\(r&gt;1\\) the fixed point \\(N^*=0\\) is monotonically unstable. For \\(r&lt;1\\) the fixed point \\(N^*=0\\) is monotonically unstable. As expected this result is consistent with the simulation results in Figure 1.1.\nFor cobweb diagram:\n\nSketch axes and label with \\(N_t\\) and \\(N_{t+1}\\).\nFrom linear stablity analysis note there are two qualitatively distinct cases (\\(r&lt;1\\) and \\(r&gt;1\\)). We will need a cobweb diagram for each case.\nCase 1: graph the function \\(H(N_t)\\). In this case it is the straight line \\(N_{t+1}=rN_t\\) with \\(r&lt;1\\).\nCase 2: graph the function \\(H(N_t)\\). In this case it is the straight line \\(N_{t+1}=rN_t\\) with \\(r&gt;1\\).\nFill in the cobwebbed trajectories with some arbitraily chosen initial condition.\nEstablish that behaviour of the cobweb is consistent with linear stability analysis.\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=3.0\nr=0.5\nr_2=1.5\nN_max=4.0\n\ndef rhs(x,r):\n  f=r*x\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n\n  num_time_steps=t.shape[0]\n\n  CobwebSol=np.zeros((2*num_time_steps,2))\n  CobwebSol[0,0]=N_0\n  CobwebSol[0,1]=rhs(N_0,r)\n  CobwebSol[1,0]=CobwebSol[0,1]\n  CobwebSol[1,1]=CobwebSol[0,1]\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r) \n\n      sol_temp=N[i-1]\n      rhs_temp=rhs(sol_temp,r)\n      CobwebSol[2*i,0]=sol_temp\n      CobwebSol[2*i,1]=rhs_temp\n      CobwebSol[2*i+1,0]=rhs_temp\n      CobwebSol[2*i+1,1]=rhs_temp\n  return N, CobwebSol\n\nN,CobwebSol=SolveSingleDiff(t,rhs,N_0,r)\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot=rhs(N_plot,r)\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(t, N)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(CobwebSol[:,0], CobwebSol[:,1])\nax[1].plot(CobwebSol[0,0], CobwebSol[0,1],'*')\nax[1].plot([0, N_max], [0, N_max])\nax[1].plot(N_plot, H_N_plot)\n\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.4: A cobweb plot of the Malthusian model solution when \\(r\\)=0.5. (a) Time series and (b) Cobweb diagrams.\n\n\n\n\nFor bifurcation diagram:\n\nWe will plot the value of fixed point against a parameter of interest. In this case \\(N^*\\) against \\(r\\).\nDeduce from fixed point and linear stability analysis whether there are any changes in solution behaviour as \\(r\\) varies (e.g. number of solution or their linear stability).\nIn this case the value of the fixed point is independent of \\(r\\) but the the linear stability changes at \\(r=1\\). This is a bifurcation.\nUse annotation to represent qualitative solution behaviour."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-nonlinear-model-of-population-dynamics-in-discrete-time",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-nonlinear-model-of-population-dynamics-in-discrete-time",
    "title": "1  Single species population dynamics",
    "section": "1.5 A nonlinear model of population dynamics in discrete time",
    "text": "1.5 A nonlinear model of population dynamics in discrete time\nConsider a model of population growth given by\n\\[\nN_{t+1}=\\frac{\\gamma N_t}{1+N_t^2},\n\\tag{1.5}\\] where \\(\\gamma\\in \\Re^+\\) is the linear growth rate.\n\n1.5.1 Numerical solution\nIn Figure 1.5 time series solution of the model are plotted for parameter values \\(\\gamma=0.5\\), \\(\\gamma=1.5\\), \\(\\gamma=2.5\\). Note qualitative changes in model behaviour in the different parameter regimes. Can you identify the fixed points? Are the solutions oscillatory?\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\n\nN_0=3.0\ngam_1=0.5\ngam_2=1.5\ngam_3=2.5\n\ndef rhs(x,r):\n  f=r*x/(1+x**2)\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r) \n  return N\n\nN_1=SolveSingleDiff(t,rhs,N_0,gam_1)\nN_2=SolveSingleDiff(t,rhs,N_0,gam_2)\nN_3=SolveSingleDiff(t,rhs,N_0,gam_3)\n\n\nfig, ax = plt.subplots(1,3)\nax[0].plot(t, N_1)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[2].plot(t, N_3)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.5: Time series solution for (a) \\(g\\)=0.5 and (b) \\(g\\)=1.5 and (c) \\(g\\)=10.5.\n\n\n\n\n\n\n1.5.2 Fixed points\nThe fixed points satisfy the algebraic equation \\[\nN^*=\\frac{\\gamma N^*}{1+{N^*}^2}\n\\] which has solutions \\[\nN^* = 0  \\ \\ \\ \\ \\textrm{and} \\ \\ \\ \\ N^*=\\sqrt{\\gamma-1}.\n\\]\nSketch a graph of \\(H(N_t)\\) against \\(N_t\\) in the cases \\(\\gamma&lt;1\\) and \\(\\gamma&gt;1\\).\nNote that the per capita growth rate is described by the function \\[\nf(N_{t})=\\frac{\\gamma}{1+N_t^2}.\n\\] Hence at large populations the per capita growth rate tends to zero whilst for small populations it tends to \\(\\gamma\\). Hence so long as \\(\\gamma&gt;1\\) we will have net growth for small populations and net removal for large populations. The net growth rate is given by \\[\nH(N_{t})=\\frac{\\gamma N_t}{1+N_t^2}.\n\\]\n\n\n1.5.3 Parameter restrictions for biological validity\nIf \\(\\gamma&lt;1\\), there is only one biologically relevant fixed point. If \\(\\gamma &gt;1\\) there are two fixed-points, \\(N^*=0\\) and \\(N^*=\\sqrt{\\gamma-1}\\). Hence the value of the model parameter \\(\\gamma\\) qualitatively affects the behaviour and number of solutions.\nSketch a graph of \\(N^*\\) against \\(\\gamma\\).\nRoots: 0 TP:\n\n\n1.5.4 Linear stability analysis\nFor the given model we compute \\[\nH'(N_t)= \\frac{\\gamma}{1+N_t^2} + \\frac{-2 \\gamma N_t^2}{(1+N_t^2)^2}.\n\\]\n\n1.5.4.1 \\(N^*=0\\)\nThe stability of the fixed point \\(N^*=0\\) is determined by \\[\nH'(0)= \\gamma.\n\\] Hence if $ &lt;1$ the first fixed point is monotonically stable as \\(0&lt;H'(0) &lt; 1\\).\nWhen \\(\\gamma &gt; 1\\) the second fixed point becomes biologically relevant and the first fixed point becomes monotonically unstable.\n\n\n1.5.4.2 \\(N^*=\\sqrt{\\gamma-1}\\)\nThe stability of the second fixed point, \\(N^*=\\sqrt{\\gamma-1}\\), is determined by\n\nHence if \\(N^*\\) were monotonically unstable,\n\\[\nH'(\\sqrt{\\gamma-1}) = \\frac{2}{\\gamma}-1 &gt;1,\n\\] and \\[\n\\gamma&lt;1.\n\\] As a necessary condition for the biological relevance of \\(N^*\\) is that \\(\\gamma&gt;1\\) we obtain a contradiction. Hence \\(N^*\\), if it is biologically relevant, cannot be monotonically unstable.\nSuppose \\(N^*\\) is monotonically stable. Then \\[\n0&lt;H'(N^*) &lt;1\n\\] which upon substitution yields \\[\n0&lt;\\frac{2}{\\gamma}-1  &lt;1.\n\\] Hence \\(1&lt;\\gamma&lt;2\\). Suppose \\(N^*\\) is oscillatory stable. Then \\[\n-1&lt;H'(N^*) &lt;0\n\\] which upon substitution yields \\[\n-1&lt;\\frac{2}{\\gamma}-1  &lt; 0.\n\\] Hence \\(\\gamma&gt;2\\). Hence the linear stability of the fixed point \\(N^*=\\sqrt{\\gamma-1}\\) depends on whether \\(\\gamma\\) lies in the range \\([0,1]\\), \\([1,2 ]\\) or \\([2,\\infty]\\).\nLet’s annotate the diagram in the previous figure with the info. obtained from the linear stability analysis. Hence the interval \\([0,\\infty]\\) can be divided into distinct subintervals within which the linear stability of \\(N^*\\) is conserved. The boundaries of subintervals are bifurcation values where a the stability of the fixed point changes.\n\n\n\n1.5.5 Cobweb diagrams\nIn Figure 1.6 cobweb diagrams illustrate model behaviour in the three different parameter regimes. Note that the cobweb diagrams can be sketched by hand, given an accurate enough sketch of the right-hand side function \\(H(N_t)\\). Note also that the cobweb diagrams are consistent with the linear stability analysis but that the linear approximation is only valid close to the equilibrium point.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=0.2\nr_1=0.5\nr_2=1.5\nr_3=2.5\nr_4=3.5\n\nN_max=4.0\n\ndef rhs(x,r):\n  f=r*x/(1+x**2)\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n\n  num_time_steps=t.shape[0]\n\n  CobwebSol=np.zeros((2*num_time_steps,2))\n  CobwebSol[0,0]=N_0\n  CobwebSol[0,1]=rhs(N_0,r)\n  CobwebSol[1,0]=CobwebSol[0,1]\n  CobwebSol[1,1]=CobwebSol[0,1]\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r) \n\n      sol_temp=N[i-1]\n      rhs_temp=rhs(sol_temp,r)\n      CobwebSol[2*i,0]=sol_temp\n      CobwebSol[2*i,1]=rhs_temp\n      CobwebSol[2*i+1,0]=rhs_temp\n      CobwebSol[2*i+1,1]=rhs_temp\n  return N, CobwebSol\n\nN1,CobwebSol1=SolveSingleDiff(t,rhs,N_0,r_1)\nN2,CobwebSol2=SolveSingleDiff(t,rhs,N_0,r_2)\nN3,CobwebSol3=SolveSingleDiff(t,rhs,N_0,r_3)\nN4,CobwebSol4=SolveSingleDiff(t,rhs,N_0,r_4)\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot1=rhs(N_plot,r_1)\nH_N_plot2=rhs(N_plot,r_2)\nH_N_plot3=rhs(N_plot,r_3)\nH_N_plot4=rhs(N_plot,r_4)\n\nfig, ax = plt.subplots(2,2)\n\nax[0,0].plot(CobwebSol1[:,0], CobwebSol1[:,1])\nax[0,0].plot(CobwebSol1[0,0], CobwebSol1[0,1],'*')\nax[0,0].plot([0, N_max], [0, N_max])\nax[0,0].plot(N_plot, H_N_plot1)\n\nax[0,1].plot(CobwebSol2[:,0], CobwebSol2[:,1])\nax[0,1].plot(CobwebSol2[0,0], CobwebSol2[0,1],'*')\nax[0,1].plot([0, N_max], [0, N_max])\nax[0,1].plot(N_plot, H_N_plot2)\n\nax[1,0].plot(CobwebSol3[:,0], CobwebSol3[:,1])\nax[1,0].plot(CobwebSol3[0,0], CobwebSol3[0,1],'*')\nax[1,0].plot([0, N_max], [0, N_max])\nax[1,0].plot(N_plot, H_N_plot3)\n\nax[1,1].plot(CobwebSol4[:,0], CobwebSol4[:,1])\nax[1,1].plot(CobwebSol4[0,0], CobwebSol4[0,1],'*')\nax[1,1].plot([0, N_max], [0, N_max])\nax[1,1].plot(N_plot, H_N_plot4)\n\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.6: Cobweb diagrams for different values of gamma.\n\n\n\n\n\n\n1.5.6 Bifurcation diagram\nBifurcations at the critical values \\(\\gamma=1\\) and \\(\\gamma=2\\) are highlighted in the bifurcation diagram presented in Figure 1.7. Note that the bifurcation diagram allows classification of the different model behaviours in a single plot without explicitly calculating the solution to the model.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\ngam_plot=np.linspace(0,4,100)\nN_star_1=0*np.zeros_like(gam_plot)\n\ngam_plot2=np.linspace(1,4,100)\nN_star_2=np.sqrt(gam_plot2-1)\n\nfig, ax = plt.subplots(1)\n\nax.plot(gam_plot,N_star_1)\nax.plot(gam_plot2,N_star_2)\n\n\nplt.xlabel('$gamma$')\nplt.ylabel('$N^*$')\nplt.show()\n\n\n\n\n\nFigure 1.7: A bifiurcation diagram."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#an-application---how-much-harvesting-can-a-population-sustain",
    "href": "MA32009-SinglePopDiscreteTimea.html#an-application---how-much-harvesting-can-a-population-sustain",
    "title": "1  Single species population dynamics",
    "section": "1.6 An application - how much harvesting can a population sustain?",
    "text": "1.6 An application - how much harvesting can a population sustain?\nModels of population dynamics can be used to study how interventions will affect population dynamics. Extending from the model developed in the previous example, a valid question might be what is the maximal rate of harvesting a fish stock can sustain without becoming extinct? ### Including a harvesting term Introducing a harvesting term at per capita harvesting rate \\(h\\), the governing model equation becomes \\[\nN_{t+1}=\\frac{\\gamma N_t}{1+N_t^2} - h N_t,\n\\tag{1.6}\\]\nand the questions we want to ask are: (i) does the introduction of harvesting change the dynamics of the system?; and (ii) what rate of harvesting such a population could withstand?\n\n1.6.1 Direct simulation\nBased on the previous analysis we consider the system in a parameter regime where without harvesting there is a stable fixed point (\\(\\gamma&gt;1\\)).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\n\nN_0=0.1\ngam=5.0\nh_1=0.1\nh_2=1.0\nh_3=3.0\n\ndef rhs(x,r,h):\n  f=r*x/(1+x**2)-h*x\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r,h):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r,h) \n  return N\n\nN_1=SolveSingleDiff(t,rhs,N_0,gam,h_1)\nN_2=SolveSingleDiff(t,rhs,N_0,gam,h_2)\nN_3=SolveSingleDiff(t,rhs,N_0,gam,h_3)\n\n\nfig, ax = plt.subplots(1,3)\nax[0].plot(t, N_1)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[2].plot(t, N_3)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.8: Time series solution for (a) \\(g\\)=0.5 and (b) \\(g\\)=1.5 and (c) \\(g\\)=10.5.\n\n\n\n\nIn Figure 1.8 time series solutions at increasing harvesting rates (\\(h=0.1\\), \\(h=1\\), \\(h=3\\)) are presented. For low harvesting rates the system behaves almost identically to the no harvesting case but with an expected reduction in the fixed point value. However for intermediate harvesting the population undergoes oscillations. However, for further increased harvesting rates there appears again to be a stable fixed point.\nCan analysis of the model help us understand how/why changes in solutions occur?\n\n\n1.6.2 Fixed points\nThe fixed points of the system satisfy \\[\nN^*=\\frac{\\gamma N^*}{1+{N^*}^2} - h N^*.\n\\] Hence the fixed points are \\[\nN^*=0\n\\] and \\[\nN^*=\\sqrt{\\frac{\\gamma}{1+h}-1}.\n\\] Note that harvesting lowers the population size of the non-zero fixed point (when it exists).\nCan we deduce a condition that must hold on the parameters \\(\\gamma\\) and \\(h\\) in order that there is a non trivial biologically relevant fixed point?\nRequiring \\[\nN^* &gt;0\n\\] implies \\[\n\\frac{\\gamma}{1+h}-1&gt;0\n\\].\n\n\n1.6.3 Linear stability\nThe linear stability is determined by \\[\nH'(N_t)=\\frac{\\gamma }{1+{N_t}^2} - \\frac{2\\gamma N_t^2 }{(1+{N_t}^2)^2} - h.\n\\] At \\(N^*=0\\) we obtain \\[\nH'(0)=\\gamma-h.\n\\] Hence if \\(\\gamma&gt;1+h\\), \\(N^*=0\\) is unstable.\nNote that this is the condition that determines whether the non-zero fixed point exists or not.\nAt \\[\nN^*=\\sqrt{\\frac{\\gamma}{1+h}-1},\n\\]\n\\[\nH'\\left(\\sqrt{\\frac{\\gamma}{1+h}-1}\\right)=\\frac{\\gamma }{1+\\frac{\\gamma}{1+h}-1} - \\frac{2\\gamma \\frac{\\gamma}{1+h}-1 }{(1+\\frac{\\gamma}{1+h}-1)^2} - h.\n\\] Hence linear stability is a function of two parameters \\(\\gamma\\) and \\(h\\).\nWe can show that\n\\[\nH'(N^*) = h^2\\frac{2}{\\gamma} + h\\frac{2}{\\gamma}(2-\\gamma) + \\frac{2}{\\gamma}-1,\n\\]{#harvestingH_prime} and hence that when \\(h=0\\) we retrieve the stability condition from the previous model.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nh_vec=np.linspace(0.1,5,100)\ngamma_1=(1+h_vec)**2/h_vec\ngamma_2=1+h_vec\ngamma_3=h_vec\n\nfig, ax = plt.subplots(1)\nax.plot(h_vec, gamma_1)\nax.plot(h_vec, gamma_2)\nax.plot(h_vec, gamma_3)\n\nplt.xlabel('$h$')\nplt.ylabel('$\\gamma$')\nplt.show()\n\n\n\n\n\nFigure 1.9: Stability regions for the harvesting model.\n\n\n\n\n\n\n1.6.4 Stability boundaries in the \\(h\\gamma\\) plane\nThe contour at \\(H'(N^*)=1\\) can be identified by solving \\[\nh^2\\frac{2}{\\gamma} + h\\frac{2}{\\gamma}(2-\\gamma) + \\frac{2}{\\gamma}-1 = 1,\n\\] yielding \\[\n\\gamma= 1+h.\n\\]\nThe contour at \\(H'(N^*)=-1\\) can be represented by $ \\[\nh^2\\frac{2}{\\gamma} + h\\frac{2}{\\gamma}(2-\\gamma) + \\frac{2}{\\gamma}-1 = -1,\n\\] Solving for \\(\\gamma\\) yields \\[\n\\gamma=\\frac{(1+h)^2}{h}.\n\\]\nIn Figure Figure 1.9 we plot the contours of the hypersurface \\(H'(N^*)\\) at the critical values of \\(-1\\), \\(0\\) and 1. Note that the points in parameter space used to generate the simulation results in Figure \\(\\ref{HarvestingTimeSeries}\\) are \\((h,\\gamma)=(0.1,5)\\) \\((h,\\gamma)=(1,5)\\) and \\((h,\\gamma)=(3,5)\\). Cobweb diagrams in different regions of parameter space are presented in Figure \\(\\ref{HarvestingCobweb}\\). The plot in Figure 1.9 can be used to explain why the model transfers from a stable fixed point, through oscillatory fixed point and back to a stable fixed point as the harvesting rate increases from 0.1, to \\(1\\) and then 5?\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=0.2\nh_1=0.1\nh_2=1.0\nh_3=3.0\nr=5.0\n\nN_max=4.0\n\ndef rhs(x,r,h):\n  f=r*x/(1+x**2)-h*x\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r,h):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n  num_time_steps=t.shape[0]\n\n  CobwebSol=np.zeros((2*num_time_steps,2))\n  CobwebSol[0,0]=N_0\n  CobwebSol[0,1]=rhs(N_0,r,h)\n  CobwebSol[1,0]=CobwebSol[0,1]\n  CobwebSol[1,1]=CobwebSol[0,1]\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r,h) \n\n      sol_temp=N[i-1]\n      rhs_temp=rhs(sol_temp,r,h)\n      CobwebSol[2*i,0]=sol_temp\n      CobwebSol[2*i,1]=rhs_temp\n      CobwebSol[2*i+1,0]=rhs_temp\n      CobwebSol[2*i+1,1]=rhs_temp\n  return N, CobwebSol\n\nN1,CobwebSol1=SolveSingleDiff(t,rhs,N_0,r,h_1)\nN2,CobwebSol2=SolveSingleDiff(t,rhs,N_0,r,h_2)\nN3,CobwebSol3=SolveSingleDiff(t,rhs,N_0,r,h_3)\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot1=rhs(N_plot,r,h_1)\nH_N_plot2=rhs(N_plot,r,h_2)\nH_N_plot3=rhs(N_plot,r,h_3)\n\nfig, ax = plt.subplots(1,3)\n\nax[0].plot(CobwebSol1[:,0], CobwebSol1[:,1])\nax[0].plot(CobwebSol1[0,0], CobwebSol1[0,1],'*')\nax[0].plot([0, N_max], [0, N_max])\nax[0].plot(N_plot, H_N_plot1)\n\nax[1].plot(CobwebSol2[:,0], CobwebSol2[:,1])\nax[1].plot(CobwebSol2[0,0], CobwebSol2[0,1],'*')\nax[1].plot([0, N_max], [0, N_max])\nax[1].plot(N_plot, H_N_plot2)\n\nax[2].plot(CobwebSol3[:,0], CobwebSol3[:,1])\nax[2].plot(CobwebSol3[0,0], CobwebSol3[0,1],'*')\nax[2].plot([0, N_max], [0, N_max])\nax[2].plot(N_plot, H_N_plot3)\n\n\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.10: Cobweb diagrams for different values of h.\n\n\n\n\nWe can construct a cobweb diagram for the case \\((h,\\gamma)=(3,5)\\)."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-note-on-the-modelling-of-real-world-fish-stocks",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-note-on-the-modelling-of-real-world-fish-stocks",
    "title": "1  Single species population dynamics",
    "section": "1.7 A note on the modelling of real-world fish stocks",
    "text": "1.7 A note on the modelling of real-world fish stocks\nYou can find reports on fish stocks (measurements and modelling work) from the International Council for the Exploration of the Sea at the link http://www.ices.dk/Pages/default.aspx. Here’s a link to the data for Atlantic salmon https://tinyurl.com/ya8sh72j. Note that although the models we have worked on are not detailed enough to accurately model real fish population dynamics, many of the principles we have covered arise in the cutting edge models."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#oscillations",
    "href": "MA32009-SinglePopDiscreteTimea.html#oscillations",
    "title": "1  Single species population dynamics",
    "section": "1.8 Oscillations",
    "text": "1.8 Oscillations\nLinear stability analysis describes the evolution of small perturbations close to a fixed point. But far from a fixed point the nonlinear terms that were dropped in a Taylor expansion are no longer negligible. In particular, in the case where \\(H'(N^*)&lt;-1\\), it can be the case that regions of parameter space in which a fixed point is oscillatory unstable can give rise to periodic and chaotic solutions.\n### Defining a periodic solution Consider the general form \\[\nN_{t+1}=H(N_t)\n\\tag{1.7}\\] A solution to Equation 1.7 isdefined to be periodic with period \\(T\\) if\n\\[\n\\begin{aligned}\nN_{t+T}&=N_t \\ \\  \\forall t,\nN_{t+\\tau}&\\neq N_t  \\ \\ \\forall t, \\  \\ \\ \\tau&lt;T.\n\\end{aligned}\n\\]\nPeriod 2 solutions can be identified by looking for solutions that repeat after two iterations. Suppose \\(\\bar{N}\\) is a period 2 solution of Equation 1.7 and let \\(\\bar{N}=N_1\\). Then \\[\nN_{2}=H(\\bar{N}).\n\\] However, \\[\nN_{3}=H(N_2)=H(H(\\bar{N}))\n\\] and if \\(\\bar{N}\\) is a period 2 solution \\(N_3=N_1=\\bar{N}\\). Hence period 2 solutions can be calculated by solving the algebraic equation \\[\n\\bar{N}=H(H(\\bar{N})).\n\\] Note that period two solutions are fixed points of the problem \\[\nN_{t+2}=H^2(N_t)=g(N_t).\n\\] Using the tools we have developed, period solutions and their stability can be determined. Furthermore, longer period solutions can be identified by generalising the argument but at the expense of ever increasingly complicated right-hand side functions. In many systems, such as the harvesting model and the logistic equation, increasing the growth rate parameter leads initially to the fixed point becoming unstable and the emergence of period two solutions, then period 4 solutions and so on until eventually there is a transition to chaotic solutions (see, for example, Figure 1.11).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=40\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=0.1\nr_1=9.68\nr_2=12.221\nr_3=30.25\nh=0.1\n\nN_max=20.0\n\ndef rhs(x,r,h):\n  f=r*x/(1+x**2)-h*x\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,r,h):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n\n  num_time_steps=t.shape[0]\n\n  CobwebSol=np.zeros((2*num_time_steps,2))\n  CobwebSol[0,0]=N_0\n  CobwebSol[0,1]=rhs(N_0,r,h)\n  CobwebSol[1,0]=CobwebSol[0,1]\n  CobwebSol[1,1]=CobwebSol[0,1]\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r,h) \n\n      sol_temp=N[i-1]\n      rhs_temp=rhs(sol_temp,r,h)\n      CobwebSol[2*i,0]=sol_temp\n      CobwebSol[2*i,1]=rhs_temp\n      CobwebSol[2*i+1,0]=rhs_temp\n      CobwebSol[2*i+1,1]=rhs_temp\n  return N, CobwebSol\n\nN1,CobwebSol1=SolveSingleDiff(t,rhs,N_0,r_1,h)\nN2,CobwebSol2=SolveSingleDiff(t,rhs,N_0,r_2,h)\nN3,CobwebSol3=SolveSingleDiff(t,rhs,N_0,r_3,h)\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot1=rhs(N_plot,r_1,h)\nH_N_plot2=rhs(N_plot,r_2,h)\nH_N_plot3=rhs(N_plot,r_3,h)\n\nfig, ax = plt.subplots(3,2)\n\nax[0,0].plot(t, N1)\n\nax[0,1].plot(CobwebSol1[:,0], CobwebSol1[:,1])\nax[0,1].plot(CobwebSol1[0,0], CobwebSol1[0,1],'*')\nax[0,1].plot([0, N_max], [0, N_max])\nax[0,1].plot(N_plot, H_N_plot1)\n\nax[1,0].plot(t, N2)\n\nax[1,1].plot(CobwebSol2[:,0], CobwebSol2[:,1])\nax[1,1].plot(CobwebSol2[0,0], CobwebSol2[0,1],'*')\nax[1,1].plot([0, N_max], [0, N_max])\nax[1,1].plot(N_plot, H_N_plot2)\n\nax[2,0].plot(t, N3)\n\nax[2,1].plot(CobwebSol3[:,0], CobwebSol3[:,1])\nax[2,1].plot(CobwebSol3[0,0], CobwebSol3[0,1],'*')\nax[2,1].plot([0, N_max], [0, N_max])\nax[2,1].plot(N_plot, H_N_plot3)\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.11: Transition form period 2 to period 4 solutions in the harvesting model\n\n\n\n\nExercise: identify an equation satisfied by period 2 solutions of the logistic map \\[\nN_{t+1}=rN_1(1-N_t).\n\\]"
  },
  {
    "objectID": "DiscreteModels2d.html",
    "href": "DiscreteModels2d.html",
    "title": "2  Multi species population dynamics",
    "section": "",
    "text": "3 Multiple species in discrete time\nIn this section we generalise the previous approach by considering the population dynamics of two interacting populations."
  },
  {
    "objectID": "DiscreteModels2d.html#a-general-model-of-two-interacting-species-in-discrete-time",
    "href": "DiscreteModels2d.html#a-general-model-of-two-interacting-species-in-discrete-time",
    "title": "2  Multi species population dynamics",
    "section": "3.1 A general model of two interacting species in discrete time",
    "text": "3.1 A general model of two interacting species in discrete time\nLet \\(N_t\\) and \\(P_t\\) represent population densities at time \\(t\\) where \\(t\\) is a discrete variable.\nWe consider governing equations of the form \\[\n\\begin{aligned}\nN_{t+1}=f(N_t,P_t), \\nonumber \\\\\nP_{t+1}=g(N_t,P_t).\n\\end{aligned}\n\\tag{3.1}\\] where the population dynamics of the species are coupled to one another via the functions \\(f\\) and \\(g\\).\nThe precise form for \\(f\\) and \\(g\\) will be defined by the biological system under study. Typical interpopulation interactions that are studied are: predator prey models, competition and cooperation."
  },
  {
    "objectID": "DiscreteModels2d.html#general-techniques-for-analysing-coupled-first-order-difference-equations",
    "href": "DiscreteModels2d.html#general-techniques-for-analysing-coupled-first-order-difference-equations",
    "title": "2  Multi species population dynamics",
    "section": "3.2 General techniques for analysing coupled first order difference equations",
    "text": "3.2 General techniques for analysing coupled first order difference equations\n\n3.2.1 Fixed points\nThe fixed points of Equation 3.3 \\((N^*,P^*)\\) satisfy \\[\n\\begin{aligned}\nN^*=g(N^*,P^*) \\nonumber \\\\\nP^*=f(N^*,P^*).\n\\end{aligned}\n\\]\n\n\n\n3.2.2 Linear stability analysis\nTo consider linear stability of a steady state we consider the change of variable \\[\n\\begin{aligned}\nN_t&=N^*+\\hat{N}_{t},   \\nonumber\\\\\nP_t&=P^*+\\hat{P}_{t}.  \\nonumber\n\\end{aligned}\n\\] After substitution in Equation 3.3 and making Taylor expansions about \\((N^*,P^*)\\) we obtain at leading order\n\\[\n\\left(\\begin{array}{c}\n\\hat{N}_{t+1} \\\\ \\hat{P}_{t+1}\\end{array}\\right) = \\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial N}&\\frac{\\partial f}{\\partial P} \\\\ \\frac{\\partial g}{\\partial N }&\\frac{\\partial g}{\\partial P} \\end{array}\\right)_{(N^*,P^*)} \\left(\\begin{array}{c} \\hat{N}_{t} \\\\ \\hat{P}_{t}\\end{array}\\right).\n\\tag{3.2}\\]\nNote the appearance of the Jacobian matrix \\[\nA= \\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial N}&\\frac{\\partial f}{\\partial P} \\\\ \\frac{\\partial g}{\\partial N }&\\frac{\\partial g}{\\partial P} \\end{array}\\right)_{(N^*,P^*)} \\left(\\begin{array}{c} \\hat{N}_{t} \\\\ \\hat{P}_{t}\\end{array}\\right).\n\\]\n\n\n3.2.3 Solving the linearised problem\nDefining \\[\n\\mathbf{w}_t=\\left(\\begin{array}{c}\\hat{N}_{t} \\\\ \\hat{P}_{t}\\end{array}\\right),\n\\]\n\\[\n\\mathbf{w}_{t+1}=A\\mathbf{w}_{t}\n\\] By solving this linear system we can investigate whether small perturbation about the fixed point grow or decay in magnitude as time evolves and hence determine the linear stability of the fixed point.\nThe solution of Equation 3.2 takes the form \\[\n\\mathbf{w}_t=\\sum_{i=1}^2 C_i \\lambda_i^t\\mathbf{c}_i,\n\\] where the \\(C_i\\)’s are constants determined by initial conditions and the \\(\\lambda_i\\)’s and \\(\\mathbf{c}_i\\)’s are the eigenvalues and eigenvectors of A, respectively. From this form we can see that if the magnitude of all eigenvalues is less than one, i.e. \\[\n|\\lambda_i|&lt;1, \\ \\ \\ \\ \\ \\forall i,\n\\] the fixed point is linearly stable. If at least one of the eigenvalues has \\(|\\lambda_i|&gt;1\\) then the fixed point is unstable to linear perturbations.\n\n\n\n3.2.4 Jury conditions\nIn many cases it is not very useful to explicitly compute the eigenvalues of the Jacobian matrix. In such cases we can employ the Jury conditions in order to determine when a fixed point is linearly stable.\nRecall that for a two dimensional matrix, the eigenvalues satisfy the quadratic characteristic equation\n\\[\n\\lambda^2- trA \\lambda + detA=0.\n\\]\nThe stability of the fixed is guaranteed if \\(|\\lambda _i|&lt;1\\) \\(\\forall i\\).\nConsider the characteristic equation \\[\nP(\\lambda)=\\lambda^2 + a \\lambda +b=0,\n\\] where \\(a,b \\in \\Re\\). Note that \\(a=-tr{A}\\) and \\(b=\\det{A}\\).\nThe Jury conditions state that \\(|\\lambda_i |&lt;1 \\forall \\ \\  i\\) if, and only if, * \\(b&lt;1\\), * \\(1+a+b&gt;0\\), * *\\(1-a+b&gt;0\\). See Figure \\(\\ref{JuryConditions}\\) for schematic diagram.\n\n\n3.2.5 Proof of the Jury conditions\nThe roots of \\(P(\\lambda)\\) are \\[\n\\lambda_{1,2}=\\frac{-a \\pm \\sqrt{a^2-4b}}{2}.\n\\]\n\n\n3.2.6 Complex roots\nSuppose \\(a^2-4b&lt; 0\\). The roots are complex. Since \\(b\\) is equal to the product of the roots, we find that\n\\[\nb=\\lambda_1\\lambda_2 = |\\lambda_1|^2 = |\\lambda_2^2|.\n\\] Hence \\(\\lambda_i&lt;1\\) \\(\\forall \\ \\ i\\) if and only if \\(b&lt;1\\).\nFor the other conditions we introduce the identity: \\[\na^2-4b=(|a|-2)^2 - 4(1+b-|a|).\n\\] Therefore, when \\(a^2-4b&lt;0\\), the inequality requires \\[\n(|a|-2)^2 - 4(1+b-|a|)&lt;0.\n\\] This can only occur if \\[\n1+b-|a| &gt;0 \\implies 1+b-a&gt;0 \\ \\ \\textrm{and} \\ \\  1+b+a&gt;0.\n\\]\n\n\n3.2.7 Real roots\nSuppose \\(a^2-4b\\geq 0\\)\nThe largest magnitude of the roots is \\[\nR=\\max\\{|\\lambda_1|,|\\lambda_2|\\} =  \\frac{|a| + \\sqrt{a^2-4b}}{2}.\n\\] This is an increasing function of \\(|a|\\).\n\\(R=1\\) \\[\n\\implies  \\frac{|a| + \\sqrt{a^2-4b}}{2}=1\n\\implies |a|-2=-\\sqrt{|a|^2-4b}\n\\implies |a|^2-4|a|+4=|a|^2-4b\n\\implies |a|=b+1.\n\\] Hence \\(0\\leq R &lt; 1\\) if and only if \\(0\\leq |a|&lt;1+b\\). Also, since \\(|\\lambda_i|&lt;1 \\forall i\\) implies that \\(|\\lambda_1\\lambda_2|&lt;1\\), it follows that \\(|b|&lt;1\\) must hold."
  },
  {
    "objectID": "DiscreteModels2d.html#host-parasitoid-infection",
    "href": "DiscreteModels2d.html#host-parasitoid-infection",
    "title": "2  Multi species population dynamics",
    "section": "3.3 Host Parasitoid infection",
    "text": "3.3 Host Parasitoid infection\nParasitoids are creatures that have a free living and parasitic stage. The free-living adult lays eggs in a host that later hatch and develop after eating the host. The discrete stages of the parasitoids life cycle and the dependence on its reproduction on the availability of host suggest a discrete time, multi species models. Let \\(N_{t}\\) and \\(P_t\\) represent the number of hosts and parasitoids at time \\(t\\), respectively. Let \\(R_0\\) represent the reproductive ratio of host in the absence of parasites and \\(C\\) the average number of viable eggs laid by each parasite on a host. ### Model equations\nWe consider equations of the form \\[\n\\begin{aligned}\nN_{t+1}&=R_0N_t f(N_t,P_t), \\nonumber \\\\\nP_{t+1}&=CN_t (1- f(N_t,P_t)). \\nonumber\n\\end{aligned}\n\\tag{3.3}\\]\nThe justification for this form is that at a given time \\(t\\) there are \\(N_t\\) hosts. A total of \\(N_t f(N_t,P_t)\\) escape the parasite and are able to reproduce whilst a total of \\(N_t(1-f(N_t,P_t))\\) do not escape the parasite and lead to parasitic reproduction at the next time step.\nChoosing \\[\nf(N_t,P_t)=e^{-aP_t},\n\\] yields the Nicholson Bailey model \\[\n\\begin{aligned}\nN_{t+1}=R_0N_t e^{-aP_t}, \\nonumber \\\\\nP_{t+1}=CN_t (1- e^{-aP_t}).\n\\end{aligned}\n\\tag{3.4}\\]\n\n\n3.3.1 Fixed points\nThe fixed points satisfy \\[\n\\begin{aligned}\nN^*=R_0N^*e^{-aP^*}, \\nonumber \\\\\nP^*=CN^* (1- e^{-aP^*}).\n\\end{aligned}\n\\]\nThe first equation yields \\[\nN^*=0.\n\\]\nSuppose \\(N^*\\neq 0\\) \\[\n1=R_0e^{-aP^*}.\n\\]\nHence \\[\nP^*=\\frac{1}{a}\\ln R_0.\n\\]\nConsider the second equation. Suppose \\(N^*=0\\). We obtain \\[\nP^*=0.\n\\] Hence one fixed point is \\((0,0)\\).\nSuppose \\(P^*=\\frac{1}{a}\\ln R_0\\). \\[\n\\frac{1}{a}\\ln R_0 = CN^*(1-\\frac{1}{R_0}).\n\\] Hence \\[\nN^* = \\frac{\\frac{1}{a}\\ln R_0 }{C(1-\\frac{1}{R_0})} = \\frac{R_0\\ln R_0 }{aC(R_0-1)}.\n\\] Hence the second fixed point is \\[\n\\left(\\frac{R_0\\ln R_0 }{aC(R_0-1)},\\frac{1}{a} \\ln R_0 \\right).\n\\]\nWe can verify by substitution that \\[\n\\left(\\frac{R_0\\ln R_0 }{aC(R_0-1)},\\frac{1}{a} \\ln R_0 \\right).\n\\] is a fixed point. We can then deduce a condition on the model parameters that must hold in order that the fixed point is biologically relevant.\nTo verify by substitution we substitute the proposed solution into the governing equations. Note that \\[\ne^{-aP^*}=\\frac{1}{R_0}.\n\\] In this case \\[\n\\begin{aligned}\n\\frac{R_0\\ln R_0 }{aC(R_0-1)}=R_0 \\frac{R_0\\ln R_0 }{aC(R_0-1)}\\frac{1}{R_0}, \\nonumber \\\\\n\\frac{1}{a} \\ln R_0=C\\frac{R_0\\ln R_0 }{aC(R_0-1)} (1-\\frac{1}{R_0}).\n\\end{aligned}\n\\tag{3.5}\\]\nCancellation shows that both equations hold. Hence the fixed point is a valid fixed point. To be biologically relevant we require that both components of the solution are real and positive. In this case this leads to the condition \\(R_0&gt;1\\)}.\n\n\n3.3.2 Linear stability\nThe Jacobian matrix is given by \\[\nA_{(N_t,P_t)}= \\left(\\begin{array}{cc}\nR_0e^{-aP_t}&-R_0aN_te^{-aP_t} \\\\ c(1-e^{-aP_t})&aCN_te^{-aP_t} \\end{array}\\right).\n\\]\n\n\n3.3.3 Linear stability of the trivial fixed point\nEvaluating at (0,0) yields \\[\nA= \\left(\\begin{array}{cc}\nR_0 & 0 \\\\ 0 & 0 \\end{array}\\right).\n\\] Hence the eigenvalues are \\(R_0\\) and 0. If \\(0&lt;R_0&lt;1\\) (0,0) is stable whilst if \\(R_0&gt;1\\) (0,0) is unstable.\n\n\n3.3.4 Linear stability of the nontrivial fixed point\nWe can show that the Jacobian matrix evaluated at the nontrivial fixed point can be written as \\[\nA= \\left(\\begin{array}{cc}\n1&-\\frac{R_0 \\ln R_0}{c(R_0-1)} \\\\ c(1-\\frac{1}{R_0})&\\frac{\\ln R_0}{R_0-1} \\end{array}\\right) .\n\\] and deduce that the eigenvalues of A satisfy the characteristic polynomial \\[\n\\lambda^2 - \\lambda\\left(1+\\frac{\\ln R_0}{R_0-1}\\right)+ \\frac{R_0\\ln(R_0)}{R_0-1}=0.\n\\]\n\n\n\n\n3.3.5 Employing the Jury conditions\nTo proceed with linear stability analysis we employ the Jury conditions. Consider the polynomial \\[\n\\lambda^2+a\\lambda+b=0,\n\\] In our case \\[\na= - (1+\\frac{\\ln R_0}{R_0-1})\n\\] and \\[\nb=\\frac{R_0\\ln(R_0)}{R_0-1}.\n\\]\nThe third Jury condition (\\(b&lt;1\\)) implies that for linear stability \\[\n\\ln R_0 &lt; 1-\\frac{1}{R_0}.\n\\] To demonstrate that this inequality is not true for \\(R_0&gt;1\\), let \\(f_1=\\ln R_0\\) and \\(f_2=1- 1/R_0\\). When \\(R_0=1\\), \\(f_1=f_2=0\\). However, \\[\nf_1'=\\frac{1}{R_0}  \\ \\ \\textrm{and} \\ \\ f_2'=\\frac{1}{R_0^2},\n\\] implies \\[\nf_1'&gt;f_2'  \\ \\ \\forall \\ R_0&gt;1.\n\\] Hence \\[\n\\ln R_0 &gt; 1-\\frac{1}{R_0}.\n\\] Hence the fixed point is unstable if \\(R_0&gt;1\\). %Note that the general conditions for stability are known as the Jury conditions."
  },
  {
    "objectID": "enzymekinetics.html#the-law-of-mass-action",
    "href": "enzymekinetics.html#the-law-of-mass-action",
    "title": "5  Enzyme kinetics",
    "section": "5.1 The law of mass action",
    "text": "5.1 The law of mass action\nWe denote the \\(i^{th}\\) chemical species using the notation \\(C_i\\). The concentration of molecule type \\(C_i\\) is denoted \\([C_i]\\) and represents the number of molecules of \\(C_i\\) per unit volume.\nSuppose \\(C_1,..C_M\\) undergo the reaction\n\\[\n\\lambda_1C_1+\\lambda_2 C_2+...+\\lambda_m C_M \\xrightleftharpoons[k_{b}]{k_{f}}\n\\gamma_1 C_1+\\gamma_2 C_2 + ... \\gamma_M C_M.\n\\]\nthe law of mass action states that the forward reaction proceeds at rate\n\\[\nk_f[C_1]^\\lambda_1 [C_2]^\\lambda_2 ..[C_M]^\\lambda_M\n\\]\nwhilst the backward reaction proceeds at rate\n\\[\nk_b[C_1]^\\gamma_1[C_2]^\\gamma_2 ..[C_M]^\\gamma_M\n\\]\nwhere \\(k_f\\) and \\(k_b\\) are dimensional rate constants.\nExample Suppose A and B react to produce C. Hence \\[\nA+B\\xrightarrow{k}  C.\n\\]\nThe law of mass action states that the rate of the reaction is\n\\[\nk[A][B].\n\\]\nUsing the reaction rates, we write down ordinary differential equations that describe how concentrations of a given molecule will change in time. Hence\n\\[\n\\frac{d[C]}{dt}=k[A][B].\n\\]\nConsider the reversible reaction \\[\nA+B  \\xrightleftharpoons[k_{-}]{k_{+}}  C.\n\\] Define dependent variables, identify reaction rates and derive ordinary differential equations that describe how concentrations evolved in time.\nThe dependent variables are: \\[ [A](t), \\ \\ [B](t), \\ \\ [C](t) \\].\nApplying the law of mass action yields the reaction rates:\n\\[ k_+[A][B] \\ \\ \\textrm{and} \\ \\ k_-[C]\\].\nThe ODEs are\n\\[\n\\begin{align}\n\\frac{d[A]}{dt}&=-k_+[A][B]+k_-[C], \\nonumber\\\\\n\\frac{d[B]}{dt}&=-k_+[A][B]+k_-[C], \\nonumber\\\\\n\\frac{d[C]}{dt}&=k_+[A][B]-k_-[C]. \\nonumber\n\\end{align}\n\\]\nFor a given set of initial conditions, \\[\n[A](t=0)=[A]_0, \\ \\ \\ [B](t=0)=[B]_0, \\ \\ \\ [C](t=0)=[C]_0,\n\\] the ODEs can be solved and hence the concentrations of the different molecules described as time evolves.\n\n5.1.1 Example\nThe previous example have had stochiometric constants all set to unity (i.e. all reactions involved a molecules of one species interaction with one from another). Consider the reaction in which one molecule of species A with \\(m\\) of species B giving rise to \\(n\\) molecules of species B and \\(p\\) molecules of species C, i.e. \\[\nA+mB \\xrightarrow{k_1} nB + pC.\n%X \\underset{k_2}{\\stackrel{k_1}{\\rightleftharpoons}} Y\n\\]\nThe law of mass action says that the rate of the forward reaction is \\[\nk_1[A][B]^m.\n\\]\nThe governing ODEs are \\[\n\\begin{align}\n\\frac{d[A]}{dt}&=-k_1[A][B]^m, \\nonumber\\\\\n\\frac{d[B]}{dt}&=(n-m)k_1[A][B]^m, \\nonumber\\\\\n\\frac{d[C]}{dt}&=pk_1[A][B]^m.  \\nonumber\n\\end{align}\n\\]\nConsider the reversible reaction \\[\nA+A  \\xrightleftharpoons[k_{-}]{k_{+}}  B.\n\\] Define dependent variables, identify reaction rates and derive ordinary differential equations that describe how concentrations evolved in time.\nThe reaction rates are \\[\nk_+[A]^2\n\\] and \\[\nk_- [B].\n\\] The ODEs are \\[\n\\begin{align}\n\\frac{d[A]}{dt}&=-2k_+[A]^2+2k_- [B] , \\nonumber\\\\\n\\frac{d[B]}{dt}&=k_+[A]^2-k_- [B],\n\\end{align}\n\\]\n\n\n5.1.2 Enzyme kinetics\nBiochemical reactions are often regulated by enzymes (substances that convert a substrate into another substrate). Consider a chemical reaction in which substrate, \\(S\\), reacts with an enzyme, \\(E\\), to form a complex, \\(C\\). Suppose the complex can either undergo the reverse reaction or go on to form a product, \\(P\\), with the release of the enzyme, i.e. \\[\nS+E  \\xrightleftharpoons[k_{-1}]{k_{1}}  C \\xrightarrow{k_2} P+E .\n\\]\n\n\n5.1.3 Deriving the model equations\nFor notational convenience we let lower case letter denote concentrations, i.e. \n\\[\ns(t)=[S](t),  \\ \\ c(t)=[C](t) , \\\\ e(t)=[E](t), \\\\ p(t)=[P](t).\n\\]\nDemonstrate by applying the law of mass action that the above enzyme kinetic scheme can be described by the system of ODES\n\\[\n\\begin{align}\n\\frac{d s}{dt} &= -k_1 se + k_{-1}c, \\nonumber \\\\\n\\frac{d e}{dt} &= -k_1 se + k_{-1}c +k_2 c,  \\nonumber\\\\\n\\frac{d c}{dt} &= k_1 se - k_{-1}c-k_2c, \\nonumber \\\\\n\\frac{d p}{dt} &= k_2 c.\n\\label{MMenten4Var}\n\\end{align}\n\\tag{5.1}\\]\nWe consider initial conditions such that at \\(t=0\\) the reaction has not yet started, i.e. there is no product or complex formed \\[\ns(0)=s_0, \\ \\ e(0)=e_0, \\ \\ c(0)=0, \\ \\ p(0)=0,\n\\] where \\(s_0\\) and \\(e_0\\) represent the initial concentrations of substrate and enzyme, respectively.\n\n\n5.1.4 Reducing the dimensions of the model\nWhilst there are four dependent variables in the problem (\\(s(t)\\), \\(c(t)\\), \\(e(t)\\) and \\(p(t)\\)), the description of the problem can be simplified by noting that the variable \\(p(t)\\) does not couple back to the other variables, i.e. if we can solve the system for \\(s(t)\\), \\(e(t)\\) and \\(c(t)\\) then \\(c(t)\\) can be expressed as a function of time and\n\\[\np(t)=k_2\\int c(t) dt + C_1.\n\\]\nFurthermore, there is a conserved quantity in the system. Note that\n\\[\n\\frac{d e}{dt}+\\frac{d c}{dt}=0,\n\\]\nwhich reflects the fact that enzyme exists either in free form or bound to the product. Integrating yields\n\\[\nc(t)+e(t)=C_2.\n\\]\nEvaluating at \\(t=0\\),\n\\[\ne_0=C_2.\n\\]\nHence\n\\[\nc(t)+e(t)=e_0\n\\]\nand the variable \\(e(t)\\) can be replaced by\n\\[\ne(t)=e_0-c(t)\n\\]\nGiven \\[\ne(t)=e_0-c(t),\n\\] substitute in \\[\n\\begin{align}\n\\frac{d s}{dt} &= -k_1 se + k_{-1}c, \\nonumber \\\\\n\\frac{d c}{dt} &= k_1 se - k_{-1}c-k_2c, \\nonumber \\\\\n\\end{align}\n\\] Hence \\[\n\\begin{align}\n\\frac{d s}{dt} &= -k_1 s(e_0-c) + k_{-1}c, \\nonumber \\\\\n\\frac{d c}{dt} &= k_1 s(e_0-c)) - (k_{-1}+k_2)c, \\nonumber \\\\\n\\end{align}\n\\]\n\n\n5.1.5 The quasi-steady state approximation (QSSA)\nA usual approach to these equations is to assume that the timescale of complex dynamics is very fast compared to that of substrate dynamics.\nTo make the QSSA we assume that one of the variables (in this case \\(c\\)), is in equilibrium\n\\[\ndc/dt \\sim 0.\n\\]\nIn which case the second equation yields\n\\[\nc=\\frac{e_0s(t)}{s(t)+K_m},\n\\]\nwhere\n\\[\nK_m=\\frac{k_{-1}+k_2}{k_1},\n\\]\nis known as the Michaelis constant.\nDemonstrate that upon using the QSSA, the governing ODE for \\(s(t)\\) is given by\n\\[\n\\frac{ds}{dt} = -\\frac{k_2e_0s}{s+K_m}.\n\\]\nConsider \\[\n\\begin{align}\n\\frac{d s}{dt} &= -k_1 s(e_0-c) + k_{-1}c, \\nonumber \\\\\n\\end{align}\n\\] By QSSA \\[\n-k_1 s(e_0-c) + k_{-1}c=-k_2c=-k_2\\frac{e_0s(t)}{s(t)+K_m},\n\\] Hence \\[\n\\begin{align}\n\\frac{d s}{dt} &= -k_2\\frac{e_0s(t)}{s(t)+K_m}, \\nonumber \\\\\n\\end{align}\n\\] Note this could be achieved by direct substitution for \\(c(t)\\)."
  },
  {
    "objectID": "enzymekinetics.html#enzyme-kinetics-the-michaelis-menten-quasi-steady-state-approximation-qssa",
    "href": "enzymekinetics.html#enzyme-kinetics-the-michaelis-menten-quasi-steady-state-approximation-qssa",
    "title": "5  Enzyme kinetics",
    "section": "5.2 Enzyme kinetics: the Michaelis-Menten quasi-steady state approximation (QSSA)",
    "text": "5.2 Enzyme kinetics: the Michaelis-Menten quasi-steady state approximation (QSSA)\n\n5.2.1 Nondimensionalisation\nDemonstrate that nondimensionalisation using \\[\n\\tau=k_1 e_0 t, \\ \\ \\ u=\\frac{s}{s_0}, \\ \\ \\ v=\\frac{c}{e_0},\n\\] yields the ODEs \\[\n\\begin{align}\n\\frac{d u}{d\\tau} &= -u+(u+K-\\lambda)v, \\nonumber \\\\\n\\epsilon \\frac{d v}{d\\tau} &= u-(u+K)v, \\nonumber \\\\\n\\end{align}\n\\tag{5.2}\\]\nwhere \\[\n\\lambda=\\frac{k_2}{k_1 s_0}, \\ \\ \\ K=\\frac{k_{-1}+k_2}{k_1 s_0}, \\ \\ \\ \\epsilon=\\frac{e_0}{s_0}.\n\\]\n\n\n5.2.2 Asymptotic expansions: the outer solution}\nWe consider the (often realised) case where the amount of enzyme in the system is small compared with the amount of substrate, i.e. \\[\n\\epsilon \\ll 1.\n\\] The presence of the small parameter \\(\\epsilon\\) allows us to use perturbation theory to calculate approximate solutions to (mmenten2varnondim?). However, the problem is singular owing to the \\(\\epsilon dv/dt\\) term.\nA proposed outer solution \nWe propose an outer solution of the form\n\\[\n\\begin{align}\nu(\\tau;\\epsilon)=u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ... = \\sum_{n=0}^{\\infty}u_n(\\tau)\\epsilon^n, \\nonumber \\\\\nv(\\tau;\\epsilon)=v_0(\\tau) + \\epsilon v_1(\\tau) + \\epsilon^2 v_2(\\tau) + ... = \\sum_{n=0}^{\\infty}v_n(\\tau)\\epsilon^n.  \\nonumber  \n\\end{align}\n\\]\nSubstituting the expansions in (mmenten2varnondim?) yields\n\\[\n\\begin{align}\n\\frac{du_0}{d\\tau} + \\epsilon \\frac{du_1}{d\\tau} + \\epsilon^2\\frac{du_2}{d\\tau} + ... = -(u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...)+  \\nonumber \\\\ (u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...+ K-\\lambda)(v_0(\\tau) + \\epsilon v_1(\\tau) + \\epsilon^2 v_2(\\tau) + ...).  \\nonumber\n\\end{align}\n\\]\nGathering terms as coefficients of the different powers of \\(\\epsilon\\) yields\n\\[\n\\begin{align}\n\\frac{du_0}{d\\tau} + \\epsilon \\frac{du_1}{d\\tau} + ... = -u_0(\\tau)+ (u_0(\\tau)+ K-\\lambda)v_0  +\\epsilon (-u_1(\\tau) + u_1v_0+v_1u_0+v_1(K-\\lambda)) + O(\\epsilon^2), \\nonumber\n\\end{align}\n\\]\nwhere terms of order \\(\\epsilon^2\\) have been neglected.\nConsidering the \\(v\\) equation yields\n\\[\n\\begin{align}\n\\epsilon(\\frac{dv_0}{d\\tau} + \\epsilon \\frac{dv_1}{d\\tau} + \\epsilon^2\\frac{dv_2}{d\\tau} + ..) = u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...  \\nonumber \\\\ -(u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...+ K) (v_0(\\tau) + \\epsilon v_1(\\tau) + \\epsilon^2 v_2(\\tau) + ...).  \\nonumber\n\\end{align}\n\\]\nGathering terms as coefficients of the different powers of \\(\\epsilon\\) yields\n\\[\n\\begin{align}\n\\epsilon\\frac{dv_0}{d\\tau} + \\epsilon^2 \\frac{dv_1}{d\\tau} + ... = u_0(\\tau)-   u_0(\\tau)v_0(\\tau) -v_0 K  \\nonumber \\\\ +\\epsilon (u_1(\\tau) - u_0v_1 - u_1v_0 - Kv_1) + O(\\epsilon^2).  \\nonumber\n\\end{align}\n\\]\nAt \\(O(1)\\)\n\\[\n\\begin{align}\n\\frac{du_0}{d\\tau} = -u_0+ (u_0+ K-\\lambda)v_0  \\nonumber \\\\\n0= u_0 - u_0 v_0 -v_0K.    \\nonumber\n\\end{align}\n\\]\nSolving the algebraic equation yields\n\\[\nv_0=\\frac{u_0}{u_0+K},\n\\]\nand substituting in the \\(u_0\\) equation yields\n\\[\n\\frac{du_0}{d\\tau} = -u_0+ (u_0+ K-\\lambda)\\frac{u_0}{u_0+K} = -\\frac{\\lambda u_0}{u_0+K}.\n\\]\nIntegrating yields\n\\[\nu_0+K\\ln u_0=-\\lambda \\tau +A,\n\\]\nwhere \\(A\\) is an integration constant.\nWhen posing a solution as an expansion, a necessary question to ask is when the expansion is a valid? On the outer scale we have shown that \\[\nv_0=\\frac{u_0}{u_0+K}.\n\\]\nNote that the expression\n\\[\nv_0=\\frac{u_0}{u_0+K}\n\\]\ndoes not satisfy the initial condition \\(v(0)=0\\). As \\(u_0(0)=1\\), we find that at \\(\\tau=0\\)\n\\[\nv_0=\\frac{1}{1+K} \\neq 0.\n\\]\nHence the proposed expansion is not valid at least near \\(\\tau=0\\).\n\n\n5.2.3 Asymptotic expansions: the inner solution\nThis issue can be rectified by proposing a different scaling for time and recalculating a series solution in the new coordinate system.\nWe proceed by making the change of variable \\[\n\\sigma=\\frac{\\tau}{\\epsilon}.\n\\]\nNote that \\(\\sigma=1\\) corresponds to \\(\\tau=\\epsilon\\). Hence the proposed rescaling of time will give rise to what is called the inner solution to the problem (close to \\(t=0\\)).\nTo distinguish inner and outer solutions we relabel dependent variables such that\n\\[\n\\begin{align}\nu(\\tau;\\epsilon)=U(\\sigma;\\epsilon),  \\nonumber \\\\\nv(\\tau;\\epsilon)=V(\\sigma;\\epsilon). \\nonumber\n\\end{align}\n\\]\n}\nNote that \\[\n\\frac{d}{d\\tau}=\\frac{1}{\\epsilon}\\frac{d}{d\\sigma}.\n\\] Hence upon changing variables \\[\n\\begin{align}\n\\frac{1}{\\epsilon}\\frac{d U}{d\\sigma} &= -\\epsilon U+ \\epsilon (U+K-\\lambda)V, \\nonumber \\\\\n\\frac{1}{\\epsilon}\\ \\epsilon \\frac{d V}{d\\sigma} &= U-(U+K)V.  \n\\end{align}\n\\] Tidying yields the requested form.\nWe seek series solutions to equations \\(\\eqref{LongTimeUV}\\) of the form\n\\[\n\\begin{align}\nU(\\sigma;\\epsilon)&=U_0(\\sigma) + \\epsilon U_1(\\sigma) + \\epsilon^2 U_2(\\sigma) + ... = \\sum_{n=0}^{\\infty}U_n(\\sigma)\\epsilon^n, \\nonumber \\\\\nV(\\sigma;\\epsilon)&=V_0(\\sigma) + \\epsilon V_1(\\sigma) + \\epsilon^2 V_2(\\sigma) + ... = \\sum_{n=0}^{\\infty}V_n(\\sigma)\\epsilon^n. \\nonumber  \n\\end{align}\n\\]\nSubstitution yields \\[\n\\begin{align}\n\\frac{dU_0}{d\\sigma}+ \\epsilon\\frac{dU_1}{d\\sigma}+ ..... &= \\epsilon\\left( U_0+\\epsilon U_1 + ... + (U_0+\\epsilon U_1+ +K-\\lambda)(V_0+\\epsilon V_1+...)\\right) \\\\\n\\frac{dV_0}{d\\sigma}+ \\epsilon\\frac{dV_1}{d\\sigma}+ ..... &= (U_0+\\epsilon U_1+...)-(U_0+\\epsilon U_1+...+K)(V_0+\\epsilon V_1+...).\n\\end{align}\n\\]\nHence at leading order \\[\n\\begin{align}\n\\frac{dU_0}{d\\sigma}&=0  \\nonumber\\\\\n\\frac{dV_0}{d\\sigma}&=U_0-(U_0+K)V_0.\n\\end{align}\n\\]\nGiven the initial condition \\(U(0)=1\\) we obtain that the inner solution is\n\\[\nU(\\sigma)=1.\n\\]\nSubstituting in the second equation gives\n\\[\n\\frac{dV_0}{d\\sigma}=1-(1+K)V_0.\n\\]\nGiven \\(V_0(0)=0\\) we obtain\n\\[\nV_0=\\frac{1-e^{-(1+K)\\sigma}}{1+K}.\n\\]\n\n\n5.2.4 Asymptotic expansions: matching the inner and outer solutions\nInner and outer solutions are matched by taking limits \\[\n\\lim_{\\tau \\rightarrow 0}(u_0(\\tau),v_0(\\tau))=\\lim_{\\sigma \\rightarrow \\infty}(U_0(\\sigma),V_0(\\sigma)).\n\\]\nNote that\n\\[\n\\lim_{\\sigma\\rightarrow \\infty} V_0(\\sigma)= \\lim_{\\sigma\\rightarrow \\infty}  \\frac{1-e^{-(1+K)\\sigma}}{1+K} = \\frac{1}{1+K},\n\\]\nand\n\\[\n\\lim_{\\tau\\rightarrow 0}(v_0(\\tau)) =\\lim_{\\tau\\rightarrow 0}\\frac{u_0}{u_0+K} =  \\frac{1}{1+K}.\n\\]\nHence the \\(v\\) variables are already matching in the appropriate limit.\nSimilarly\n\\[\n\\lim_{\\sigma\\rightarrow \\infty} U_0(\\sigma)= 1,\n\\]\nhence we require that\n\\[\n\\lim_{\\tau \\rightarrow 0} u_0(\\tau)= 1.\n\\]\nHence for\n\\[\n(u_0+K\\ln u_0=-\\lambda \\tau +A)\n\\]\nto hold as \\(\\tau \\rightarrow 0\\) implies \\(A=1\\)."
  },
  {
    "objectID": "enzymekinetics.html#the-brusselator",
    "href": "enzymekinetics.html#the-brusselator",
    "title": "5  Enzyme kinetics",
    "section": "5.3 The Brusselator",
    "text": "5.3 The Brusselator\nThe Brusselator is an abstract model that can be used to demonstrate oscillations in (bio)-chemical systems. Consider a chemical reaction where five chemical species, A, B, D, X and Y, react according to the scheme \\[\n\\begin{align}\nA&\\xrightarrow{k_{1}} X,  \\nonumber \\\\\nB+X&\\xrightarrow{k_{2}} Y+D, \\nonumber\\\\\n2X+Y&\\xrightarrow{k_{3}} 3X, \\nonumber\\\\\nX&\\xrightarrow{k_{4}} E.\n\\end{align}\n\\]\nAssuming that the concentration of A and B (\\([A]\\) and \\([B]\\), respectively) are in vast excess (i.e. the amount that A and B get depleted by the reactions is negligible compared with the total amount of A and B present), their concentration are treated as constants. Furthermore, as D and E are products but not reactants (they only appear on the right-hand side of reactions) we do not concern ourselves with their dynamics.\n\n5.3.1 Deriving model equations\nTo make the steps leading to ODEs obvious, it is useful to rewrite the reaction scheme in the form \\[\n\\begin{align}\nA&\\xrightarrow{k_{1}} X,  \\nonumber \\\\\nB+X&\\xrightarrow{k_{2}} Y+D, \\nonumber\\\\\nX+X+Y&\\xrightarrow{k_{3}} X+X+X, \\nonumber\\\\\nX&\\xrightarrow{k_{4}} E.\n\\end{align}\n\\]\nApplying the law of mass action yields that the four reactions occur at rates:\n\n\\(k_1[A]\\),\n\\(k_2[B][X]\\),\n\\(k_3[X]^2[Y]\\),\n\\(k_4[X]\\).\n\nThe total time derivative of \\([X]\\) is obtained by visiting each X in the reaction scheme once and adding the corresponding reaction rate to the right-hand side of the ODE, i.e.\n\\[  \n\\begin{align}\n\\frac{d[X]}{dt} &= \\overbrace{k_1[A]}^{R1-lhs} - \\overbrace{k_2[B][X]}^{R2-lhs} -  \\overbrace{k_3[X]^2[Y]}^{R3-lhs} - \\overbrace{k_3[X]^2[Y]}^{R3-lhs} + \\overbrace{k_3[X]^2[Y]}^{R3-rhs}+ \\overbrace{k_3[X]^2[Y]}^{R3-rhs}+ \\overbrace{k_3[X]^2[Y]}^{R3-rhs} -\\overbrace{k_4[X]}^{R4-lhs}, \\nonumber \\\\\n        &= k_1[A] - k_2[B][X] + k_3[X]^2[Y]   -k_4[X].\n\\end{align}\n\\]\nSimilarly for species Y we obtain that the total rate of change in time is \\[\n\\begin{align}\n  \\frac{d[Y]}{dt}=k_2[B][X]-k_3[X]^2[Y].\n\\end{align}\n\\]\n\n\n5.3.2 Nondimensionalisation\nUpon making the change of variables \\[\\begin{align}\nx=\\sqrt{\\frac{k_3}{k_4}}[X], \\ \\ \\ \\ \\ y=\\sqrt{\\frac{k_3}{k_4}}[Y], \\ \\ \\textrm{and} \\ \\ \\tau=k_4 t,\n\\end{align}\\] yields \\[\\begin{align}\n\\frac{d x}{d \\tau} &= a-bx+x^2y-x = f(x,y), \\\\\n\\frac{d y}{d \\tau} &= bx-x^2y = g(x,y),\n\\label{BrussNondim}\n\\end{align}\\]\nwhere \\[\na=[A]\\frac{k_1}{k_4}\\sqrt{\\frac{k_3}{k_4}} \\ \\ \\ \\textrm{and} \\ \\ \\ b= [B]\\frac{k_2}{k_4}.\n\\]\n\n\n5.3.3 vSteady states and linear stability analysis\nSeeking steady states \\((x^*,y^*)\\) of equations \\(\\eqref{BrussNondim}\\) such that \\[\nf(x^*,y^*)=g(x^*,y^*)=0\n\\] yields\n\\[\n(x^*,y^*)=(a,\\frac{b}{a}).\n\\]\n\n5.3.3.1 Linear stability analysis\nThe Jacobian matrix is\n\\[\nA=\\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial x}&\\frac{\\partial f}{\\partial y} \\\\ \\frac{\\partial g}{\\partial x }&\\frac{\\partial g}{\\partial y} \\end{array}\\right) = \\left(\\begin{array}{rr}\n-b+2xy-1&x^2\\\\ b-2xy &-x^2\\end{array}\\right).\n\\]\nEvaluating the Jacobian at \\((a,b/a)\\) yields\n\\[\nA=\n\\left(\\begin{array}{rr}\nb-1&a^2\\\\ -b &-a^2\\end{array}\\right).\n\\]\nThe determinant of the Jacobian is\n\\[\n\\det{A}=-(b-1)a^2+a^2b=a^2&gt;0,\n\\]\nHence \\((a,b/a)\\) is not a saddle. The trace of the Jacobian is \\[\n\\tr{A}=b-1-a^2.\n\\]\nHence if \\(b&gt;1+a^2\\) the trace is positive and, referring to Figure \\(\\ref{TDplane}\\), the steady state is linearly unstable. Otherwise, the steady state is linearly stable.\nIn Figure \\(\\ref{BrussNondimFig}\\) we use Maple to numerically solve equations \\(\\eqref{BrussNondim}\\) for the two cases and plot the solutions in the phase plane. Note that when the steady state is unstable, the numerical solution indicates that the system has limit cycle solutions. A valid question to ask is whether one can prove that this is the case.\n\n\n5.3.3.2 Applying the Poincaire-Bendixson theorem\nRecall that the Poincaire-Bendixson theorem can be used to prove the existence of limit cycle solutions in a case where a bounding set encloses a single unstable steady state. Hence given the case of the Brusselator with \\(b&gt;a^2+1\\), the identification of a bounding set will allow application of the Poincaire-Bendixson theorem and hence prove the existence of limit cycle solutions.\nWe begin by defining the nullclines of the system. The \\(x\\) nullcline is given by\n\\[\ny=\\frac{1+b}{x}-\\frac{a}{x^2}.\n\\]\n\n \nThe normal to this line segment is [0,1]. As CD lies in a region of the phase plane where \\(dy/dt&lt;0\\),\n\\[\n\\mathbf{n}.[\\frac{dx}{dt},\\frac{dy}{dt}] = \\frac{dy}{dt}&lt;0.\n\\]\nHence trajectories point inwards on the line segment CD.\nLet E be a point that sits on the \\(x\\) nullcline at some position \\((\\delta,(\\delta(1+b)-a)/(\\delta^2))\\) such that DE is a straight line with outwardly pointing normal vector \\([1,1]\\). Along DE\n\\[\n\\mathbf{n}.[\\frac{dx}{dt},\\frac{dy}{dt}] =   a-bx+x^2y-x + bx-x^2y = a-x&lt;0\n\\]\nfor \\(x&gt;a\\). As \\(k&gt;a\\), \\(x&gt;a\\) for all points on DE, hence trajectories point inwards on DE. Finally, consider the line segment EA which has normal vector \\(\\mathbf{n}=[1,0]\\). As \\(dx/dt&lt;0\\) along EA\n\\[\n\\mathbf{n}.[\\frac{dx}{dt},\\frac{dy}{dt}] =  \\frac{dx}{dt} &lt;0.\n\\]\nHence at all points on the closed loop ABCDEA trajectories point inwards (see Figure \\(\\ref{BrusselatorBoundingRegion}\\)). Hence ABDCEA is a confined set and the Poincaire-Bendixson theorem states that the system exhibits limit cycle solutions when the steady state is unstable. This is precisely the behaviour that we see numerically in Figure \\(\\ref{BrussNondimFig}\\). Note that the parameter \\(\\delta\\) can be determined explicitly by finding the intersection between the \\(x\\) nullcline and the line segment DE."
  }
]